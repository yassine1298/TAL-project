{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u1.txt', 'u2.txt']\n",
      "['If a digital payments company wanted to detect the occurrence or potential for fraud in its system, it could employ machine learning tools for this purpose. The computational algorithm data  built into a computer model will process all transactions happening on the digital platform, find patterns in the data set, and point out any anomaly detected by the pattern.\\n\\nDeep learning, a subset of machine learning, utilizes a hierarchical level of artificial data  neural networks to carry out the process of machine learning. The artificial neural networks are built like the human brain, with neuron nodes connected together like a web. While traditional programs build analysis with data in a linear way, the hierarchical function of deep learning systems enables machines to process data with a nonlinear approach.j', 'Data are units of information, often numeric, that are collected through observation. In a more technical sense, data are a set of values of qualitative or quantitative variables about one or more persons or objects, while a datum (singular of data) is a single value of a single variable.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = \"./Corpus\"\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "names=[]\n",
    "for dataset in data_dir_list:\n",
    "  names.append(dataset)\n",
    "#print(names)\n",
    "Files2=[]\n",
    "\n",
    "for file in data_dir_list:\n",
    "    with open(data_path+'/'+ file,  \"r\") as fileToRead:\n",
    "        fileToRead=fileToRead.read()\n",
    "        \n",
    "    Files2.append(fileToRead)\n",
    "    \n",
    "print(names)    \n",
    "print(Files2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['if', 'a', 'digital', 'payments', 'company', 'wanted', 'to', 'detect', 'the', 'occurrence', 'or', 'potential', 'for', 'fraud', 'in', 'its', 'system', 'it', 'could', 'employ', 'machine', 'learning', 'tools', 'for', 'this', 'purpose', 'the', 'computational', 'algorithm', 'data', 'built', 'into', 'a', 'computer', 'model', 'will', 'process', 'all', 'transactions', 'happening', 'on', 'the', 'digital', 'platform', 'find', 'patterns', 'in', 'the', 'data', 'set', 'and', 'point', 'out', 'any', 'anomaly', 'detected', 'by', 'the', 'pattern', 'deep', 'learning', 'a', 'subset', 'of', 'machine', 'learning', 'utilizes', 'a', 'hierarchical', 'level', 'of', 'artificial', 'data', 'neural', 'networks', 'to', 'carry', 'out', 'the', 'process', 'of', 'machine', 'learning', 'the', 'artificial', 'neural', 'networks', 'are', 'built', 'like', 'the', 'human', 'brain', 'with', 'neuron', 'nodes', 'connected', 'together', 'like', 'a', 'web', 'while', 'traditional', 'programs', 'build', 'analysis', 'with', 'data', 'in', 'a', 'linear', 'way', 'the', 'hierarchical', 'function', 'of', 'deep', 'learning', 'systems', 'enables', 'machines', 'to', 'process', 'data', 'with', 'a', 'nonlinear', 'approach', 'j'], ['data', 'are', 'units', 'of', 'information', 'often', 'numeric', 'that', 'are', 'collected', 'through', 'observation', 'in', 'a', 'more', 'technical', 'sense', 'data', 'are', 'a', 'set', 'of', 'values', 'of', 'qualitative', 'or', 'quantitative', 'variables', 'about', 'one', 'or', 'more', 'persons', 'or', 'objects', 'while', 'a', 'datum', 'singular', 'of', 'data', 'is', 'a', 'single', 'value', 'of', 'a', 'single', 'variable']]\n"
     ]
    }
   ],
   "source": [
    "u=-1\n",
    "listOfTokens=[]\n",
    "listOfTokensForfreqDist=[]\n",
    "for i in data_dir_list:\n",
    "    listOfTokens.append(re.findall(r'\\b\\w[\\w-]*\\b', Files2[u+1].lower()))\n",
    "    listOfTokensForfreqDist.extend(re.findall(r'\\b\\w[\\w-]*\\b', Files2[u+1].lower()))\n",
    "    u+=1\n",
    "\n",
    "print(listOfTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrer les mots  de rechrehes: data\n"
     ]
    }
   ],
   "source": [
    "word2find = input(\"Entrer les mots  de rechrehes: \").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant? 2\n"
     ]
    }
   ],
   "source": [
    "left = input(\"Avant? \") # This asks for the context of words on either side to grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apres? 2\n"
     ]
    }
   ],
   "source": [
    "right = input(\"Apres? \") # This asks for the context of words on either side to grab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeConc(word2conc,list2FindIn,data_dir,concList,Files,right,left): \n",
    "    u=-1\n",
    "    concl=[]\n",
    "    for i in data_dir:\n",
    "        end = len(list2FindIn[u+1])\n",
    "        o=list2FindIn[u+1]\n",
    "        sequences = {'seq{}'.format(idx): i.split() for idx, i in enumerate([word2find])}\n",
    "        count=0\n",
    "        for idx in range(len(o)):\n",
    "            for k, v in sequences.items():\n",
    "                if idx + len(v) < len(o) and o[idx: idx+len(v)] == v:\n",
    "                    #print(k, idx)\n",
    "                    if(idx==0):\n",
    "                        cont=o[idx:idx+(int(right)+1)]+list('...')\n",
    "                    else:\n",
    "                        cont=list('...')+o[idx-int(left):idx+(int(right)+1)]+list('...')\n",
    "\n",
    "                    concordanceLine = ' '.join(cont)\n",
    "                    count=count+1\n",
    "                    concl.append(concordanceLine) \n",
    "        if(count>0):\n",
    "            print('Dans le Fichier ',Files[u+1],'est fréquenté : ',count,'fois')\n",
    "        u+=1\n",
    "    concList.extend(concl)\n",
    "        \n",
    "    return concList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dans le Fichier  u1.txt est fréquenté :  5 fois\n",
      "Dans le Fichier  u2.txt est fréquenté :  3 fois\n",
      "La liste des concordances:\n",
      ". . . computational algorithm data built into . . .\n",
      ". . . in the data set and . . .\n",
      ". . . of artificial data neural networks . . .\n",
      ". . . analysis with data in a . . .\n",
      ". . . to process data with a . . .\n",
      "data are units . . .\n",
      ". . . technical sense data are a . . .\n",
      ". . . singular of data is a . . .\n"
     ]
    }
   ],
   "source": [
    "conc=[]\n",
    "makeConc(word2find,listOfTokens,data_dir_list,conc,names,right,left)\n",
    "\n",
    "print('La liste des concordances:')\n",
    "for i in conc:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 12),\n",
       " ('the', 9),\n",
       " ('of', 9),\n",
       " ('data', 8),\n",
       " ('learning', 5),\n",
       " ('or', 4),\n",
       " ('in', 4),\n",
       " ('are', 4),\n",
       " ('to', 3),\n",
       " ('machine', 3),\n",
       " ('process', 3),\n",
       " ('with', 3),\n",
       " ('digital', 2),\n",
       " ('for', 2),\n",
       " ('built', 2),\n",
       " ('set', 2),\n",
       " ('out', 2),\n",
       " ('deep', 2),\n",
       " ('hierarchical', 2),\n",
       " ('artificial', 2),\n",
       " ('neural', 2),\n",
       " ('networks', 2),\n",
       " ('like', 2),\n",
       " ('while', 2),\n",
       " ('more', 2),\n",
       " ('single', 2),\n",
       " ('if', 1),\n",
       " ('payments', 1),\n",
       " ('company', 1),\n",
       " ('wanted', 1),\n",
       " ('detect', 1),\n",
       " ('occurrence', 1),\n",
       " ('potential', 1),\n",
       " ('fraud', 1),\n",
       " ('its', 1),\n",
       " ('system', 1),\n",
       " ('it', 1),\n",
       " ('could', 1),\n",
       " ('employ', 1),\n",
       " ('tools', 1),\n",
       " ('this', 1),\n",
       " ('purpose', 1),\n",
       " ('computational', 1),\n",
       " ('algorithm', 1),\n",
       " ('into', 1),\n",
       " ('computer', 1),\n",
       " ('model', 1),\n",
       " ('will', 1),\n",
       " ('all', 1),\n",
       " ('transactions', 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#l’affichage de la liste des fréquences des mots\n",
    "fdist = FreqDist(word.lower() for word in listOfTokensForfreqDist)\n",
    "ff = fdist.most_common(50) \n",
    "ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le fichier a enregistrer\n"
     ]
    }
   ],
   "source": [
    "#exportation de la liste de concordenance\n",
    "nameOfResults = word2find.capitalize() + \"_Concordance.txt\"\n",
    "\n",
    "with open(nameOfResults, \"w\") as fileToWrite:\n",
    "    for line in conc:\n",
    "        fileToWrite.write(line + \"\\n\")\n",
    "    \n",
    "print(\"Le fichier a enregistrer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
